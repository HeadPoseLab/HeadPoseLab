# Data
data_root: ./data
sequence_length: 16
overlap: true  # use sliding window with stride 1 to enlarge samples
train_ratio: 0.7
val_ratio: 0.15
seed: 42
image_size: 128

# Dataloader
batch_size: 8
num_workers: 4
sampler:
  balanced: true

# Model
model:
  backbone: hybrid_cnn_resnet  # hybrid_cnn_resnet
  resnet_variant: resnet50     # fixed to resnet50
  cnn_branch_channels: [32, 64, 128]
  feature_dim: 256             # fused feature dim after CNN+ResNet
  fusion: concat               # concat or sum
  fusion_dropout: 0.1
  temporal_encoder: transformer # options: tcn, transformer
  tcn_channels: [192, 192]
  tcn_kernel: 3
  tcn_dilations: [1, 2]
  tcn_dropout: 0.2
  transformer:
    input_dim: null            # optional override; defaults to feature_dim
    num_layers: 2
    nhead: 4
    dim_feedforward: 512
    dropout: 0.1
    activation: relu
    use_positional_encoding: true
    pos_encoding: learned      # learned or sinusoidal
    pre_norm: true
    max_len: 256
  freeze_backbone: false
  freeze_stages: 1  # -1: no freeze, 0: stem, 1: stem+layer1, 2: +layer2, 3: +layer3, 4: full backbone
  pretrained: true

# Loss
loss:
  type: cross_entropy  # options: cross_entropy, focal
  class_weights: auto  # auto, none, or explicit list e.g. [1,1,1,1,1,1,1]
  focal_gamma: 2.0

# Optimization
train:
  epochs: 5
  lr: 0.001
  backbone_lr_scale: 0.1
  weight_decay: 0.0001
  grad_clip: 5.0
  device: auto  # auto, cpu, or cuda
  save_dir: ./checkpoints
  log_interval: 10
  log_dir: ./runs

# Evaluation
eval:
  checkpoint: ./checkpoints/best.pt
